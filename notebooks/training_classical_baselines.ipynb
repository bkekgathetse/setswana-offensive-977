{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVgpWOJVwciO",
        "outputId": "11908d77-df1d-46ac-bbea-5d2806822fe6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Cross-validation performance (on 80% training data):\n",
            " Fold 1: F1 Macro = 0.7715\n",
            " Fold 2: F1 Macro = 0.8181\n",
            " Fold 3: F1 Macro = 0.7723\n",
            " Fold 4: F1 Macro = 0.8191\n",
            " Fold 5: F1 Macro = 0.8175\n",
            "\n",
            "Best F1 Macro from CV: 0.8191\n",
            "\n",
            "Final Evaluation on 20% Holdout Set:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Non-offensive       0.80      0.83      0.81       100\n",
            "    Offensive       0.82      0.78      0.80        96\n",
            "\n",
            "     accuracy                           0.81       196\n",
            "    macro avg       0.81      0.81      0.81       196\n",
            " weighted avg       0.81      0.81      0.81       196\n",
            "\n",
            "\n",
            "Additional Metrics LogisticRegression:\n",
            "Matthews Correlation Coefficient (MCC): 0.6427\n",
            "ROC–AUC: 0.8945\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Training classical baselines with 5-fold cross-validation on an 80% training split,\n",
        "followed by final evaluation on a 20% holdout test set.\n",
        "\n",
        "Dataset (after preprocessing and splitting):\n",
        "- 477 Offensive samples\n",
        "- 500 Non-offensive samples\n",
        "\n",
        "This script assumes you already have:\n",
        "- train.csv  (80% of data), test.csv (20% holdout) combined into a single full_dataset.csv\n",
        "- This is same dataset used to Finetune transformers (PuoBERTa, Afro-XLM-R)\n",
        "\n",
        "-  stored in a local ./data/ directory.\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Directory where preprocessed CSV files are stored.\n",
        "# For public code, we assume a local ./data/ folder in the repo.\n",
        "DATA_DIR = Path(\"data\")\n",
        "\n",
        "# === Step 1: Load Dataset ===\n",
        "df = pd.read_csv('/DATA_DIR/full_dataset.csv')\n",
        "df = df[['TEXT', 'TARGET']].dropna()\n",
        "\n",
        "# === Step 2: Encode Labels ===\n",
        "le = LabelEncoder()\n",
        "df['label_encoded'] = le.fit_transform(df['TARGET'])\n",
        "\n",
        "# === Step 3: Split into 80% train_val and 20% test ===\n",
        "train_val_df, test_df = train_test_split(\n",
        "    df, test_size=0.2, stratify=df['label_encoded'], random_state=42\n",
        ")\n",
        "\n",
        "# === Step 4: Vectorize ===\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_val = vectorizer.fit_transform(train_val_df['TEXT'])\n",
        "y_train_val = train_val_df['label_encoded']\n",
        "\n",
        "X_test = vectorizer.transform(test_df['TEXT'])\n",
        "y_test = test_df['label_encoded']\n",
        "\n",
        "# === Step 5: K-Fold CV and Save Best Model ===\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "f1_scores = []\n",
        "models = []\n",
        "best_f1 = 0\n",
        "best_model = None\n",
        "\n",
        "print(\"Cross-validation performance (on 80% training data):\")\n",
        "for fold, (train_idx, val_idx) in enumerate(kf.split(X_train_val, y_train_val), 1):\n",
        "    X_train, X_val = X_train_val[train_idx], X_train_val[val_idx]\n",
        "    y_train, y_val = y_train_val.iloc[train_idx], y_train_val.iloc[val_idx]\n",
        "\n",
        "    clf = LogisticRegression(class_weight={0: 1, 1: 1}, max_iter=1000)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    y_pred = clf.predict(X_val)\n",
        "    f1 = f1_score(y_val, y_pred, average='macro')\n",
        "    f1_scores.append(f1)\n",
        "    models.append(clf)\n",
        "\n",
        "    print(f\" Fold {fold}: F1 Macro = {f1:.4f}\")\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_model = clf\n",
        "        joblib.dump(clf, f'/DATA_DIR/best_logreg_model_fold{fold}.joblib')\n",
        "\n",
        "print(f\"\\nBest F1 Macro from CV: {best_f1:.4f}\")\n",
        "\n",
        "# === Step 6: Use best model on 20% holdout ===\n",
        "y_pred_test = best_model.predict(X_test)\n",
        "print(\"\\nFinal Evaluation on 20% Holdout Set:\")\n",
        "print(classification_report(y_test, y_pred_test, target_names=le.classes_))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lyKO-4-P74FL",
        "outputId": "2f6b5bd3-582a-461d-f91d-6d348d864cf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Fold 1 F1 Score: 0.8333\n",
            "Fold 2 F1 Score: 0.8782\n",
            "Fold 3 F1 Score: 0.8077\n",
            "Fold 4 F1 Score: 0.8269\n",
            "Fold 5 F1 Score: 0.7817\n",
            "\n",
            "Final Evaluation on 20% Holdout Test Set\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Non-offensive       0.90      0.82      0.86       100\n",
            "    Offensive       0.83      0.91      0.87        96\n",
            "\n",
            "     accuracy                           0.86       196\n",
            "    macro avg       0.86      0.86      0.86       196\n",
            " weighted avg       0.87      0.86      0.86       196\n",
            "\n",
            "\n",
            "Additional Metrics MultinomialNB:\n",
            "Matthews Correlation Coefficient (MCC): 0.6427\n",
            "ROC–AUC: 0.9179\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Directory where preprocessed CSV files are stored.\n",
        "# For public code, we assume a local ./data/ folder in the repo.\n",
        "DATA_DIR = Path(\"data\")\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/DATA_DIR/full_dataset2.csv\")\n",
        "df = df[['TEXT', 'TARGET']]\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "df['label_encoded'] = le.fit_transform(df['TARGET'])\n",
        "\n",
        "# Split into 80% train+val and 20% holdout test set\n",
        "train_val_df, test_df = train_test_split(\n",
        "    df, test_size=0.2, stratify=df['label_encoded'], random_state=42\n",
        ")\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train_val = vectorizer.fit_transform(train_val_df['TEXT'])\n",
        "y_train_val = train_val_df['label_encoded'].values\n",
        "X_test = vectorizer.transform(test_df['TEXT'])\n",
        "y_test = test_df['label_encoded'].values\n",
        "\n",
        "# Cross-validation on 80% to select best model\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "best_f1 = 0\n",
        "best_model = None\n",
        "\n",
        "for fold, (train_index, val_index) in enumerate(kf.split(X_train_val, y_train_val)):\n",
        "    X_train, X_val = X_train_val[train_index], X_train_val[val_index]\n",
        "    y_train, y_val = y_train_val[train_index], y_train_val[val_index]\n",
        "\n",
        "    model = MultinomialNB()\n",
        "    model.fit(X_train, y_train)\n",
        "    y_val_pred = model.predict(X_val)\n",
        "    f1 = f1_score(y_val, y_val_pred, average='macro')\n",
        "\n",
        "    print(f\"Fold {fold+1} F1 Score: {f1:.4f}\")\n",
        "\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_model = model\n",
        "        joblib.dump(best_model, \"/DATA_DIR/best_nb_model.joblib\")\n",
        "\n",
        "# Load best model and evaluate on final holdout test set\n",
        "best_model = joblib.load(\"/DATA_DIR/best_nb_model.joblib\")\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "# Print evaluation\n",
        "print(\"\\nFinal Evaluation on 20% Holdout Test Set\")\n",
        "print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
        "\n",
        "# Additional metrics: MCC and ROC–AUC\n",
        "mcc = matthews_corrcoef(y_test, y_test_pred)\n",
        "\n",
        "# Use decision_function if available (LinearSVC); fallback to predict_proba if model supports it\n",
        "y_test_score = None\n",
        "if hasattr(best_model, \"decision_function\"):\n",
        "    y_test_score = best_model.decision_function(X_test)\n",
        "    # If decision_function returns (n_samples, n_classes), take the positive class column (1)\n",
        "    if hasattr(y_test_score, \"ndim\") and y_test_score.ndim == 2:\n",
        "        y_test_score = y_test_score[:, 1]\n",
        "elif hasattr(best_model, \"predict_proba\"):\n",
        "    y_test_score = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nAdditional Metrics MultinomialNB:\")\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
        "\n",
        "if y_test_score is not None:\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(y_test, y_test_score)\n",
        "        print(f\"ROC–AUC: {roc_auc:.4f}\")\n",
        "    except ValueError as e:\n",
        "        print(f\"ROC–AUC not computed: {e}\")\n",
        "else:\n",
        "    print(\"ROC–AUC not available (no decision_function/predict_proba for this model).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTccAtK_7IBg",
        "outputId": "35ade4ff-1531-4203-d9bb-e4fdc2488528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fold 1 F1 Macro: 0.8253\n",
            "Fold 2 F1 Macro: 0.8708\n",
            "Fold 3 F1 Macro: 0.8323\n",
            "Fold 4 F1 Macro: 0.8649\n",
            "Fold 5 F1 Macro: 0.8266\n",
            "\n",
            "Evaluating best SVM model on holdout test set...\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "Non-offensive       0.82      0.83      0.83       100\n",
            "    Offensive       0.82      0.81      0.82        96\n",
            "\n",
            "     accuracy                           0.82       196\n",
            "    macro avg       0.82      0.82      0.82       196\n",
            " weighted avg       0.82      0.82      0.82       196\n",
            "\n",
            "\n",
            "Additional Metrics SVM:\n",
            "Matthews Correlation Coefficient (MCC): 0.6427\n",
            "ROC–AUC: 0.9032\n",
            "0.6426673830951934\n",
            "0.9032291666666667\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import joblib\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/DATA_DIR/full_dataset2.csv\")\n",
        "\n",
        "# Encode string labels to numeric\n",
        "le = LabelEncoder()\n",
        "df['label_encoded'] = le.fit_transform(df['TARGET'])  # e.g., Non-offensive → 0, Offensive → 1\n",
        "\n",
        "# Split into train (80%) and holdout test set (20%)\n",
        "train_df, test_df = train_test_split(\n",
        "    df, test_size=0.2, stratify=df['label_encoded'], random_state=42\n",
        ")\n",
        "\n",
        "# TF-IDF vectorization\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "X_train = vectorizer.fit_transform(train_df['TEXT'])\n",
        "y_train = train_df['label_encoded'].values\n",
        "X_test = vectorizer.transform(test_df['TEXT'])\n",
        "y_test = test_df['label_encoded'].values\n",
        "\n",
        "# Cross-validation on 80% training data\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "best_f1 = 0\n",
        "best_model = None\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(cv.split(X_train, y_train)):\n",
        "    X_tr, X_val = X_train[train_idx], X_train[val_idx]\n",
        "    y_tr, y_val = y_train[train_idx], y_train[val_idx]\n",
        "\n",
        "    svm_clf = LinearSVC(class_weight='balanced', max_iter=10000)\n",
        "    svm_clf.fit(X_tr, y_tr)\n",
        "    y_val_pred = svm_clf.predict(X_val)\n",
        "    f1 = f1_score(y_val, y_val_pred, average='macro')\n",
        "\n",
        "    print(f\"Fold {fold+1} F1 Macro: {f1:.4f}\")\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_model = svm_clf\n",
        "        joblib.dump(best_model, 'best_svm_model.joblib')  # save best model\n",
        "\n",
        "# Load best model and evaluate on holdout set\n",
        "print(\"\\nEvaluating best SVM model on holdout test set...\")\n",
        "best_model_ = joblib.load('best_svm_model.joblib')\n",
        "y_test_pred = best_model_.predict(X_test)\n",
        "print(classification_report(y_test, y_test_pred, target_names=le.classes_))\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef, roc_auc_score\n",
        "\n",
        "# Additional metrics: MCC and ROC–AUC\n",
        "mcc = matthews_corrcoef(y_test, y_test_pred)\n",
        "\n",
        "# Use decision_function if available (LinearSVC); fallback to predict_proba if model supports it\n",
        "y_test_score = None\n",
        "if hasattr(best_model, \"decision_function\"):\n",
        "    y_test_score = best_model.decision_function(X_test)\n",
        "    # If decision_function returns (n_samples, n_classes), take the positive class column (1)\n",
        "    if hasattr(y_test_score, \"ndim\") and y_test_score.ndim == 2:\n",
        "        y_test_score = y_test_score[:, 1]\n",
        "elif hasattr(best_model, \"predict_proba\"):\n",
        "    y_test_score = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(\"\\nAdditional Metrics SVM:\")\n",
        "print(f\"Matthews Correlation Coefficient (MCC): {mcc:.4f}\")\n",
        "\n",
        "if y_test_score is not None:\n",
        "    try:\n",
        "        roc_auc = roc_auc_score(y_test, y_test_score)\n",
        "        print(f\"ROC–AUC: {roc_auc:.4f}\")\n",
        "    except ValueError as e:\n",
        "        print(f\"ROC–AUC not computed: {e}\")\n",
        "else:\n",
        "    print(\"ROC–AUC not available (no decision_function/predict_proba for this model).\")\n",
        "\n",
        "\n",
        "def get_scores_for_auc(model, X):\n",
        "    # Naive Bayes / Logistic Regression\n",
        "    if hasattr(model, \"predict_proba\"):\n",
        "        return model.predict_proba(X)[:, 1]\n",
        "    # LinearSVC\n",
        "    if hasattr(model, \"decision_function\"):\n",
        "        s = model.decision_function(X)\n",
        "        if getattr(s, \"ndim\", 1) == 2:  # rare multi-class path\n",
        "            s = s[:, 1]\n",
        "        return s\n",
        "    raise ValueError(\"Model has neither predict_proba nor decision_function.\")\n",
        "y_test_score = get_scores_for_auc(best_model_, X_test)  # scores for AUC\n",
        "\n",
        "mcc = matthews_corrcoef(y_test, y_test_pred)\n",
        "auc = roc_auc_score(y_test, y_test_score)\n",
        "\n",
        "print(mcc)\n",
        "print(auc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nfSP9HCM0bYo"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
